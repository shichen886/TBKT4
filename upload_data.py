import streamlit as st
import pandas as pd
import os
import shutil

st.set_page_config(
    page_title="ä¸Šä¼ ä¹ é¢˜æ•°æ®",
    page_icon="ğŸ“¤",
    layout="wide"
)

st.title("ğŸ“¤ ä¸Šä¼ ä¹ é¢˜æ•°æ®")
st.markdown("---")

st.header("ğŸ“‹ æ•°æ®æ ¼å¼è¦æ±‚")

col1, col2 = st.columns(2)

with col1:
    st.subheader("å¿…éœ€åˆ—")
    st.markdown("""
    | åˆ—å | ç±»å‹ | è¯´æ˜ |
    |--------|------|------|
    | `user_id` | æ•´æ•° | å­¦ç”ŸIDï¼ˆä»0å¼€å§‹ï¼‰ |
    | `item_id` | æ•´æ•° | é¢˜ç›®IDï¼ˆä»0å¼€å§‹ï¼‰ |
    | `correct` | 0æˆ–1 | ç­”é¢˜ç»“æœï¼ˆ0=é”™è¯¯ï¼Œ1=æ­£ç¡®ï¼‰ |
    | `skill_id` | æ•´æ•° | çŸ¥è¯†ç‚¹IDï¼ˆä»0å¼€å§‹ï¼‰ |
    """)

with col2:
    st.subheader("å¯é€‰åˆ—")
    st.markdown("""
    | åˆ—å | ç±»å‹ | è¯´æ˜ |
    |--------|------|------|
    | `timestamp` | æ•´æ•° | ç­”é¢˜æ—¶é—´æˆ³ |
    """)

st.markdown("---")

st.header("ğŸ“ æ•°æ®èŒƒå›´è¦æ±‚")

st.info("""
**æœ€å°è¦æ±‚ï¼š**
- è‡³å°‘ 2 ä¸ªå­¦ç”Ÿ
- æ¯ä¸ªå­¦ç”Ÿè‡³å°‘ 5 æ¬¡ç­”é¢˜
- è‡³å°‘ 2 ä¸ªä¸åŒçš„çŸ¥è¯†ç‚¹
- è‡³å°‘ 10 é“ä¸åŒçš„é¢˜ç›®

**æ¨èé…ç½®ï¼š**
- 10-1000 ä¸ªå­¦ç”Ÿ
- æ¯ä¸ªå­¦ç”Ÿ 20-200 æ¬¡ç­”é¢˜
- 5-100 ä¸ªçŸ¥è¯†ç‚¹
- 50-50000 é“é¢˜ç›®
""")

st.markdown("---")

st.header("ğŸ“¤ ä¸Šä¼ æ•°æ®")

uploaded_file = st.file_uploader(
    "é€‰æ‹© CSV æ–‡ä»¶",
    type=['csv'],
    help="è¯·ä¸Šä¼ ç¬¦åˆæ ¼å¼è¦æ±‚çš„ CSV æ–‡ä»¶"
)

if uploaded_file is not None:
    st.warning("âš ï¸ è¯·ä¸Šä¼  CSV æ–‡ä»¶")
    st.stop()

try:
    df = pd.read_csv(uploaded_file)
    
    st.subheader("ğŸ“Š æ•°æ®é¢„è§ˆ")
    st.dataframe(df.head(10))
    
    st.subheader("âœ… æ•°æ®éªŒè¯")
    
    required_columns = ['user_id', 'item_id', 'correct', 'skill_id']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        st.error(f"âŒ ç¼ºå°‘å¿…éœ€åˆ—: {', '.join(missing_columns)}")
        st.stop()
    else:
        st.success("âœ… æ‰€æœ‰å¿…éœ€åˆ—éƒ½å­˜åœ¨")
    
    num_users = df['user_id'].nunique()
    num_items = df['item_id'].nunique()
    num_skills = df['skill_id'].nunique()
    num_records = len(df)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("å­¦ç”Ÿæ•°é‡", num_users)
    with col2:
        st.metric("é¢˜ç›®æ•°é‡", num_items)
    with col3:
        st.metric("çŸ¥è¯†ç‚¹æ•°é‡", num_skills)
    with col4:
        st.metric("ç­”é¢˜è®°å½•æ•°", num_records)
    
    st.subheader("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥")
    
    checks = []
    
    if num_users < 2:
        checks.append(("âŒ", "å­¦ç”Ÿæ•°é‡å°‘äº 2 ä¸ª"))
    else:
        checks.append(("âœ…", f"å­¦ç”Ÿæ•°é‡: {num_users} ä¸ª"))
    
    records_per_user = df.groupby('user_id').size()
    min_records = records_per_user.min()
    if min_records < 5:
        checks.append(("âŒ", f"æœ‰å­¦ç”Ÿç­”é¢˜è®°å½•å°‘äº 5 æ¬¡ï¼ˆæœ€å°‘ {min_records} æ¬¡ï¼‰"))
    else:
        checks.append(("âœ…", f"æ¯ä¸ªå­¦ç”Ÿè‡³å°‘ {min_records} æ¬¡ç­”é¢˜"))
    
    if num_skills < 2:
        checks.append(("âŒ", "çŸ¥è¯†ç‚¹æ•°é‡å°‘äº 2 ä¸ª"))
    else:
        checks.append(("âœ…", f"çŸ¥è¯†ç‚¹æ•°é‡: {num_skills} ä¸ª"))
    
    if num_items < 10:
        checks.append(("âŒ", "é¢˜ç›®æ•°é‡å°‘äº 10 é“"))
    else:
        checks.append(("âœ…", f"é¢˜ç›®æ•°é‡: {num_items} é“"))
    
    if df['correct'].isin([0, 1]).all():
        checks.append(("âœ…", "correct åˆ—åªåŒ…å« 0 å’Œ 1"))
    else:
        checks.append(("âŒ", "correct åˆ—åŒ…å«é 0 æˆ– 1 çš„å€¼"))
    
    for status, message in checks:
        st.write(f"{status} {message}")
    
    all_passed = all("âœ…" in status for status, _ in checks)
    
    st.markdown("---")
    
    if all_passed:
        st.success("ğŸ‰ æ•°æ®éªŒè¯é€šè¿‡ï¼å¯ä»¥ä¸Šä¼ ")
        
        dataset_name = st.text_input(
            "æ•°æ®é›†åç§°",
            value="custom_dataset",
            help="ç”¨äºæ ‡è¯†è¿™ä¸ªæ•°æ®é›†"
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ğŸ’¾ ä¿å­˜æ•°æ®", type="primary"):
                os.makedirs('data', exist_ok=True)
                os.makedirs(f'data/{dataset_name}', exist_ok=True)
                
                save_path = f'data/{dataset_name}/preprocessed_data.csv'
                df.to_csv(save_path, sep='\t', index=False)
                
                st.success(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {save_path}")
                st.info("ğŸ’¡ ç°åœ¨å¯ä»¥åœ¨ä¸»ç³»ç»Ÿä¸­ä½¿ç”¨è¿™ä¸ªæ•°æ®é›†äº†ï¼")
        
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤æ•°æ®"):
                if os.path.exists(f'data/{dataset_name}'):
                    shutil.rmtree(f'data/{dataset_name}')
                    st.success(f"âœ… å·²æ¸…é™¤æ•°æ®é›†: {dataset_name}")
    else:
        st.error("âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ ¼å¼å’Œè¦æ±‚")
        st.warning("ğŸ’¡ æç¤ºï¼šç¡®ä¿æ‰€æœ‰æ£€æŸ¥é¡¹éƒ½é€šè¿‡åå†ä¸Šä¼ ")
    
    st.markdown("---")
    
    st.subheader("ğŸ“ æ•°æ®ç¤ºä¾‹")
    st.code("""
user_id,item_id,timestamp,correct,skill_id
0,5504,20964177,1,206
0,5479,20964214,0,206
0,5466,20964236,1,206
0,5515,20964257,1,206
0,5491,20964272,0,206
0,5472,20964349,1,206
0,5490,20964372,1,206
0,5508,20964388,1,206
0,1754,20964422,1,195
0,2803,20964440,1,195
    """, language="csv")

except Exception as e:
    st.error(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    st.info("ğŸ’¡ è¯·ç¡®ä¿ä¸Šä¼ çš„æ˜¯æœ‰æ•ˆçš„ CSV æ–‡ä»¶")

st.markdown("---")
st.caption("Â© 2024 æ™ºèƒ½çŸ¥è¯†è¿½è¸ªç³»ç»Ÿ | æ•°æ®ä¸Šä¼ å·¥å…·")
